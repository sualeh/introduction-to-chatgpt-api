{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Short Introduction to the ChatGPT API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The ChatGPT is relatively easy to use. It has object bindings in most major languages, so you can use your language of choice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To get started, create an Open AI API account, set up billing, and generate and API key at https://platform.openai.com/. Save the key to a file called \"key.txt\"\n",
    "\n",
    "Install the `openai` Python package with `pip install --upgrade openai`, and run the code below to read the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Load and set API key\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Request"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start writing your first request - you need to specify the model and provide the user prompt. \n",
    "\n",
    "The \"user\" role represents the user's input or message within the conversation. The prompt can include questions, commands, or any other content the user wants to communicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"When was the first moon landing?\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    ")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The completion has the response content, as well as usage information. Responses are messages from the \"agent\" role. What we really want to extract, though, is the actual message content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = completion.choices[0].message.content\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the \"system\" Role"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"system\" role is used to provide high-level instructions or setting the behavior of the assistant. It guides the conversation or specifies the desired outcome. This information is typically provided at the beginning of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"When was the first moon landing?\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Always reply in French.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "reply = completion.choices[0].message.content\n",
    "print(reply)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT is most useful when it has context from the conversation. You will need to maintain chat history yourself, by keeping the \"system\" and \"user\" messages as well as the \"assistant\" reponses in a list, and passing this list into every API call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintaining Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT is a REST API, and does not maintain sessions. However, the client can maintain it's own chat history, and present that on an API call for additional context on the conversation. To be effective, you would need to maintain both the user questions and the ChatGPT responses. In it's simplest form, it is a list of chat messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"What is the moon's circumference in km?\"\n",
    "\n",
    "message_history = []\n",
    "message_history.append(\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    ")\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    messages=message_history\n",
    ")\n",
    "\n",
    "# Print the response:\n",
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us store the response in the history as well, so we can make a context-sensitive prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, ask an ambiguous question, which is answered in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"How far is it?\"\n",
    "\n",
    "message_history.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=message_history\n",
    ")\n",
    "\n",
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Function Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT does not have access to real-time data such as the weather, or proprietary information from your company that you may want to access. You can use the power of ChatGPT to understand a request from the user, and call functions that you define.\n",
    "\n",
    "Let us say you have defined a function to get the weather. (In this case it returns hard-coded information.) The function can take parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you describe this function and it's parameters to ChatGPT, ChatGPT will determine the intent to use this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"What's the weather like in Boston?\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The unit for temperature\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We name and describe the function, then describe the parameters that to pass to this function. ChatGPT relies on this description to help identify whether to call the function, and what the arguments should be. \n",
    "\n",
    "If we specify `function_call=\"auto\"`, ChatGPT will try to fulfill the function parameters. If set to `none` you can force no function to be detected. \n",
    "\n",
    "\n",
    "Here is the prompt returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content = completion.choices[0]\n",
    "reply_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is no content, but instead a function call, with extracted parameters in a JSON object. It is your responsibility to call the function if you would like to do that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Based on https://github.com/Sentdex/ChatGPT-API-Basics\n",
    "- See [ChatGPT API in Python by sentdex](https://www.youtube.com/watch?v=c-g6epk3fFE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
