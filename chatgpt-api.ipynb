{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sualeh/introduction-to-chatgpt-api/blob/colab/chatgpt-api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l50CdqTioXqF"
      },
      "source": [
        "----------\n",
        "\n",
        "> **How to Run This Notebook**\n",
        "\n",
        "To get started, create an Open AI API account, set up billing, and generate and API key at https://platform.openai.com/. If you are running the notebook locally in Visual Studio Code or other IDE, create a file called `.env`, and add a line `OPENAI_API_KEY=<your-openai-api-key>`. This key will be read by the `load_dotenv` library.\n",
        "\n",
        "Otherwise, if you are running in Google Colab, create a secret called `OPENAI_API_KEY` and set it to the value of your OpenAI API key.\n",
        "\n",
        "Run the code below to read the key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wRN0CzlrrvQ"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv\n",
        "\n",
        "from os import environ as env\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load key from an environmental variable called \"OPENAI_API_KEY\"\n",
        "# Use python-dotenv https://pypi.org/project/python-dotenv/\n",
        "# And take environment variables from .env\n",
        "load_dotenv()\n",
        "try:\n",
        "  # Attempt to read OPENAI_API_KEY from a Google Colab secret\n",
        "  from google.colab import userdata\n",
        "  env['OPENAI_API_KEY'] = env.get('OPENAI_API_KEY', userdata.get('OPENAI_API_KEY'))\n",
        "except ModuleNotFoundError:\n",
        "  print(\"Not running in Google Colab\")\n",
        "  # No action - rely on the OPENAI_API_KEY environmental variable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qae9yrErzUm"
      },
      "source": [
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P2Hkt3joXqG"
      },
      "source": [
        "# A Short Introduction to the ChatGPT API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nttO5ggIoXqH"
      },
      "source": [
        "\n",
        "The ChatGPT is relatively easy to use. It has object bindings in most major languages, so you can use your language of choice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbNHzUoeoXqH"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leu5c9BWoXqH",
        "outputId": "6322c4aa-f780-46bd-cdcf-f132b628ce47"
      },
      "outputs": [],
      "source": [
        "%pip install openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# Create Open AI client to use ChatGPT\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gio5Z92toXqH"
      },
      "source": [
        "## Making a Request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUh5FCyQoXqI"
      },
      "source": [
        "Start writing your first request - you need to specify the model and provide the user prompt.\n",
        "\n",
        "The \"user\" role represents the user's input or message within the conversation. The prompt can include questions, commands, or any other content the user wants to communicate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhRZ_jKEoXqI",
        "outputId": "50151b70-d566-4cf8-b78d-cb792369d5a9"
      },
      "outputs": [],
      "source": [
        "prompt = \"When was the first moon landing?\"\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n",
        "\n",
        "print(chat_completion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ZF6F_toXqI"
      },
      "source": [
        "The completion has the response content, as well as usage information. Responses are messages from the \"agent\" role. What we really want to extract, though, is the actual message content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySfQZSZfoXqI"
      },
      "outputs": [],
      "source": [
        "reply = chat_completion.choices[0].message.content\n",
        "print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a06E47xoXqI"
      },
      "source": [
        "## Using the \"system\" Role"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_le2j2REoXqI"
      },
      "source": [
        "The \"system\" role is used to provide high-level instructions or setting the behavior of the assistant. It guides the conversation or specifies the desired outcome. This information is typically provided at the beginning of the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aztd1x8UoXqI"
      },
      "outputs": [],
      "source": [
        "prompt = \"When was the first moon landing?\"\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Always reply in French.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ],\n",
        ")\n",
        "\n",
        "reply = chat_completion.choices[0].message.content\n",
        "print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-hLPzNmoXqJ"
      },
      "source": [
        "ChatGPT is most useful when it has context from the conversation. You will need to maintain chat history yourself, by keeping the \"system\" and \"user\" messages as well as the \"assistant\" reponses in a list, and passing this list into every API call."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG74OZ2roXqJ"
      },
      "source": [
        "## Maintaining Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rniItILoXqJ"
      },
      "source": [
        "ChatGPT is a REST API, and does not maintain sessions. However, the client can maintain it's own chat history, and present that on an API call for additional context on the conversation. To be effective, you would need to maintain both the user questions and the ChatGPT responses. In it's simplest form, it is a list of chat messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzPmssuAoXqJ"
      },
      "outputs": [],
      "source": [
        "prompt = \"What is the moon's circumference in km?\"\n",
        "\n",
        "message_history = []\n",
        "message_history.append(\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=message_history\n",
        ")\n",
        "\n",
        "# Print the response:\n",
        "reply_content = chat_completion.choices[0].message.content\n",
        "print(reply_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tQsAND2oXqJ"
      },
      "source": [
        "Let us store the response in the history as well, so we can make a context-sensitive prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cmknrhFoXqJ"
      },
      "outputs": [],
      "source": [
        "message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWTtpUUpoXqJ"
      },
      "source": [
        "Now, ask an ambiguous question, which is answered in context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOS0XV3yoXqJ"
      },
      "outputs": [],
      "source": [
        "prompt = \"How far is it?\"\n",
        "\n",
        "message_history.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=message_history\n",
        ")\n",
        "\n",
        "reply_content = chat_completion.choices[0].message.content\n",
        "print(reply_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b50L7nMoXqJ"
      },
      "source": [
        "## References\n",
        "\n",
        "- Based on [Sentdex/ChatGPT-API-Basics](https://github.com/Sentdex/ChatGPT-API-Basics)\n",
        "- See [ChatGPT API in Python by sentdex](https://www.youtube.com/watch?v=c-g6epk3fFE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
