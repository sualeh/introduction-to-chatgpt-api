{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sualeh/introduction-to-chatgpt-api/blob/colab/chatgpt-rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAaoVeg0yZ7L"
      },
      "source": [
        "----------\n",
        "\n",
        "> **How to Run This Notebook**\n",
        "\n",
        "To get started, create an Open AI API account, set up billing, and generate and API key at https://platform.openai.com/. If you are running the notebook locally in Visual Studio Code or other IDE, create a file called `.env`, and add a line `OPENAI_API_KEY=<your-openai-api-key>`. This key will be read by the `load_dotenv` library.\n",
        "\n",
        "Otherwise, if you are running in Google Colab, create a secret called `OPENAI_API_KEY` and set it to the value of your OpenAI API key.\n",
        "\n",
        "Run the code below to read the key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1OiJxD4yZ7M"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv\n",
        "\n",
        "from os import environ as env\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load key from an environmental variable called \"OPENAI_API_KEY\"\n",
        "# Use python-dotenv https://pypi.org/project/python-dotenv/\n",
        "# And take environment variables from .env\n",
        "load_dotenv()\n",
        "try:\n",
        "  # Attempt to read OPENAI_API_KEY from a Google Colab secret\n",
        "  from google.colab import userdata\n",
        "  env['OPENAI_API_KEY'] = env.get('OPENAI_API_KEY', userdata.get('OPENAI_API_KEY'))\n",
        "except ModuleNotFoundError:\n",
        "  print(\"Not running in Google Colab\")\n",
        "  # No action - rely on the OPENAI_API_KEY environmental variable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN0hAxFVyZ7N"
      },
      "source": [
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x0CJrN-yZ7N"
      },
      "source": [
        "# Retrieval-Augmented Generation (RAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5ydcl3yZ7N"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azZaEz0TyZ7N"
      },
      "outputs": [],
      "source": [
        "%pip install openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# Create Open AI client to use ChatGPT\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQX9HQMGyZ7N"
      },
      "source": [
        "## Embedding\n",
        "\n",
        "Convert your text into an embedding vector. An embedding vector is a vector of floating point values. These vectors are used to represent words with similar meanings close to each other. That is, the distance between these vectors captures some of the semantic relationships between the words.\n",
        "\n",
        "By default, the length of the embedding vector will be 1536 for text-embedding-3-small or 3072 for text-embedding-3-large. You can reduce the dimensions of the embedding by passing in the dimensions parameter without the embedding losing its concept-representing properties. (From [What are Embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veilx8QXyZ7N"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
        "   text = text.replace(\"\\n\", \" \")\n",
        "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
        "\n",
        "print(get_embedding(\"Hello, World!\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR-DSxb-yZ7N"
      },
      "source": [
        "A simple cosine function can find similarity between vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cetj3kXnyZ7O"
      },
      "outputs": [],
      "source": [
        "%pip install scipy\n",
        "\n",
        "from scipy import spatial\n",
        "\n",
        "def cosine_similarity(vector1, vector2):\n",
        "    return 1 - spatial.distance.cosine(vector1, vector2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0LFHkS-yZ7O"
      },
      "source": [
        "## Find Similarity\n",
        "\n",
        "Find the embedding vectors between the user query and blocks of content, and then find the most similar content. If there is a question being asked, this is where the answer is likely to be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6d7P1GsyZ7O"
      },
      "outputs": [],
      "source": [
        "quotes = [\n",
        "    '\"Stop worrying about the potholes in the road and enjoy the journey\" - Babs Hoffman.',\n",
        "    '\"A journey of a thousand miles begins with a single step\" - Chinese proverb',\n",
        "    '\"One small step for man, one giant leap for mankind.\" - Neil Armstrong'\n",
        "]\n",
        "user_query = \"What's a famous saying about a long trip?\"\n",
        "\n",
        "# Encode the query\n",
        "query_vector = get_embedding(user_query)\n",
        "\n",
        "# Calculate cosine similarities between the user query and the quotes\n",
        "scores = []\n",
        "for i, quote in enumerate(quotes):\n",
        "    vector = get_embedding(quote)\n",
        "    similarity = cosine_similarity(query_vector, vector)\n",
        "    print(f'{quote[:50]}â€¦ - {similarity}')\n",
        "    scores.append((similarity, quote))\n",
        "\n",
        "# Find most similar text by sorting to find the highest similarity score\n",
        "scores.sort(reverse=True)\n",
        "most_similar_text = scores[0][1]\n",
        "\n",
        "print()\n",
        "print(f'The text most similar to the query:\\n\\t{user_query}\\nis:\\n\\t{most_similar_text}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0dATT1ZyZ7O"
      },
      "source": [
        "Embeddings can saved for future use. For large datasets, use a vector database. Vector databases can quickly find the vectors in the database that are most similar to a given query vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gv7A_-MyZ7O"
      },
      "source": [
        "## Complete With Context Using ChatGPT\n",
        "\n",
        "Use the most similar text to be efficient with the completion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zZR6aSwyZ7O"
      },
      "outputs": [],
      "source": [
        "user_prompt = \"What's a famous saying about a long trip? How many steps start a journey? Answer with a numeric value.\"\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": most_similar_text},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        ")\n",
        "\n",
        "reply = chat_completion.choices[0].message.content\n",
        "print(reply)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
