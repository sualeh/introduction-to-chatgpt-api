{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, create an Open AI API account, set up billing, and generate and API key at https://platform.openai.com/. Create a file called `.env`, and add a line `OPENAI_API_KEY=<your-openai-api-key>`. This key will be read by the `load_dotenv` library.\n",
    "\n",
    "Install the `openai` Python package with `pip -r requirements.txt`, and run the code below to read the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load key from an environmental variable called \"OPENAI_API_KEY\"\n",
    "# Use python-dotenv https://pypi.org/project/python-dotenv/\n",
    "# And take environment variables from .env\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "Convert your text into an embedding vector. An embedding vector is a vector of floating point values. These vectors are used to represent words with similar meanings close to each other. That is, the distance between these vectors captures some of the semantic relationships between the words. \n",
    "\n",
    "By default, the length of the embedding vector will be 1536 for text-embedding-3-small or 3072 for text-embedding-3-large. You can reduce the dimensions of the embedding by passing in the dimensions parameter without the embedding losing its concept-representing properties. (From [What are Embeddings](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "print(get_embedding(\"Hello, World!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple cosine function can find similarity between vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    return 1 - spatial.distance.cosine(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similarity\n",
    "\n",
    "Find the embedding vectors between the user query and blocks of content, and then find the most similar content. If there is a question being asked, this is where the answer is likely to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    '\"Stop worrying about the potholes in the road and enjoy the journey\" - Babs Hoffman.',\n",
    "    '\"A journey of a thousand miles begins with a single step\" - Chinese proverb',\n",
    "    '\"One small step for man, one giant leap for mankind.\" - Neil Armstrong'\n",
    "]\n",
    "user_query = \"What's a famous saying about a long trip?\"\n",
    "\n",
    "# Encode the query\n",
    "query_vector = get_embedding(user_query)\n",
    "\n",
    "# Calculate cosine similarities between the user query and the quotes\n",
    "scores = []\n",
    "for i, quote in enumerate(quotes):\n",
    "    vector = get_embedding(quote)\n",
    "    similarity = cosine_similarity(query_vector, vector)\n",
    "    print(f'{quote[:25]}â€¦ - {similarity}')\n",
    "    scores.append((similarity, quote))\n",
    "\n",
    "# Find most similar text by sorting to find the highest similarity score\n",
    "scores.sort(reverse=True)\n",
    "most_similar_text = scores[0][1]\n",
    "\n",
    "print()\n",
    "print(f'The text most similar to the query:\\n\\t{user_query}\\nis:\\n\\t{most_similar_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings can saved for future use. For large datasets, use a vector database. Vector databases can quickly find the vectors in the database that are most similar to a given query vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete With Context Using ChatGPT\n",
    "\n",
    "Use the most similar text to be efficient with the completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"How many steps start a journey? Answer with a numeric value\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": most_similar_text},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "reply = chat_completion.choices[0].message.content\n",
    "print(reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
